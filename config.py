import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N TH√îNG MINH ---
# 1. ∆Øu ti√™n d·ªØ li·ªáu t·∫°m tr√™n Colab (T·ªëc ƒë·ªô cao)
if os.path.exists("/content/temp_data/flickr30k_images"):
    DATA_ROOT = "/content/temp_data/flickr30k_images"
    print(f"Dataset Root: {DATA_ROOT}")
    
    # [QUAN TR·ªåNG] Ki·ªÉm tra xem ·∫£nh n·∫±m ·ªü ƒë√¢u
    # Tr∆∞·ªùng h·ª£p 1: flickr30k_images/flickr30k_images/*.jpg (Th∆∞·ªùng g·∫∑p khi unzip)
    if os.path.exists(os.path.join(DATA_ROOT, "flickr30k_images")):
        image_dir = os.path.join(DATA_ROOT, "flickr30k_images")
    # Tr∆∞·ªùng h·ª£p 2: flickr30k_images/images/*.jpg (Code c≈© c·ªßa b·∫°n)
    elif os.path.exists(os.path.join(DATA_ROOT, "images")):
        image_dir = os.path.join(DATA_ROOT, "images")
    # Tr∆∞·ªùng h·ª£p 3: ·∫¢nh n·∫±m ngay trong DATA_ROOT
    else:
        image_dir = DATA_ROOT
        
    print(f"üëâ ƒê√£ t·ª± ƒë·ªông d√≤ t√¨m th∆∞ m·ª•c ·∫£nh t·∫°i: {image_dir}")

# 2. Ch·∫°y tr√™n Drive
elif os.path.exists("/content/drive/MyDrive/01_Dev_Projects/Video_Captioning/src/data/DatasetFlickr30k"):
    DATA_ROOT = "/content/drive/MyDrive/01_Dev_Projects/Video_Captioning/src/data/DatasetFlickr30k"
    image_dir = os.path.join(DATA_ROOT, "images") # Tr√™n Drive b·∫°n t·ª± qu·∫£n l√Ω n√™n ch·∫Øc l√† ƒë√∫ng
    print(f"ƒêang ch·∫°y Drive: {image_dir}")

# 3. Ch·∫°y Local
else:
    DATA_ROOT = os.path.join(BASE_DIR, "src", "data", "DatasetFlickr30k")
    image_dir = os.path.join(DATA_ROOT, "images")
    print(f"ƒêang ch·∫°y Local: {image_dir}")


# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n Caption (Gi·ªØ nguy√™n)
if "temp_data" in DATA_ROOT:
    caption_dir = "/content/drive/MyDrive/01_Dev_Projects/Video_Captioning/src/data/DatasetFlickr30k/captions"
else:
    caption_dir = os.path.join(DATA_ROOT, "captions")
    
# --- C·∫•u h√¨nh Encoder (ViT-Base) ---
vit_cfg = dict(
    image_size=224,      
    patch_size=16,       
    in_channels=3,
    embed_dim=768,       # Chu·∫©n Base
    depth=12,            
    num_heads=12,        
    mlp_ratio=4.0,       
    dropout=0.1          # Overfit mode: 0.0
)

# --- C·∫•u h√¨nh Decoder (Transformer) ---
trans_cfg = dict(
    dim=768,             # Kh·ªõp v·ªõi ViT
    num_heads=12,        
    num_layers=6,        
    ff_dim=3072,         
    dropout=0.1,         
    max_len=40,
    
    # [QUAN TR·ªåNG] Ph·∫£i kh·ªõp v·ªõi T5 Tokenizer ƒë·ªÉ tr√°nh l·ªói CUDA Assert
    # T5 Base m·∫∑c ƒë·ªãnh l√† 32128. (Code train s·∫Ω c·∫≠p nh·∫≠t l·∫°i s·ªë ch√≠nh x√°c t·ª´ len(tokenizer))
    vocab_size=32128     
)

# --- HU·∫§N LUY·ªÜN ---
epochs = 15